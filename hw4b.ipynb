{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f994628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class Bagging:\n",
    "    def __init__(self, t=50, depth=3):\n",
    "        self.t = t\n",
    "        self.depth = depth\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.models = [DecisionTreeClassifier(max_depth=self.depth) for _ in range(self.t)]\n",
    "        print(f'Training {self.t} decision trees!')\n",
    "        for i in range(self.t):\n",
    "            sampled_X = X.sample(frac=1, replace=True)\n",
    "            sampled_y = y[sampled_X.index]\n",
    "            self.models[i].fit(sampled_X, sampled_y)\n",
    "        return self.models\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = np.array([model.predict(X) for model in self.models])\n",
    "        preds = np.sum(preds, axis=0)\n",
    "        return (preds > 0) * 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e397023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "spambase = pd.read_csv(\"spambase.data\")\n",
    "\n",
    "spambase_train, spambase_test = train_test_split(spambase, test_size=0.3)\n",
    "spambase_train_y = spambase_train.pop('is_spam')\n",
    "spambase_test_y = spambase_test.pop('is_spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b3ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 50 decision trees!\n"
     ]
    }
   ],
   "source": [
    "test = Bagging(depth=4)\n",
    "test.train(spambase_train, spambase_train_y)\n",
    "spambase_bag_preds = test.predict(spambase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4890b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(pred_y, y):\n",
    "    df = pd.DataFrame({'preds': pred_y, 'labels': y})\n",
    "    tp = ((df['labels'] == 1) & (df['preds'] == 1)).sum()\n",
    "    tn = ((df['labels'] == 0) & (df['preds'] == 0)).sum()\n",
    "    fp = ((df['labels'] == 0) & (df['preds'] == 1)).sum()\n",
    "    fn = ((df['labels'] == 1) & (df['preds'] == 0)).sum()\n",
    "    print(f'Accuracy: {(tp + tn) / len(y)}, Error: {(fp + fn) / len(y)}')\n",
    "    print(f'TPR: {tp / (tp + fn)}, FPR: {fp / (fp + tn)}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7426beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8146270818247646, Error: 0.18537291817523532\n",
      "TPR: 0.9377289377289377, FPR: 0.26586826347305387\n"
     ]
    }
   ],
   "source": [
    "compare_results(spambase_bag_preds, spambase_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3337c",
   "metadata": {},
   "source": [
    "I was not able to match my AdaBoost performance (92% accuracy) with Bagging (87% accuracy), but it's not that far off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ffbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class GradientBoostedTrees:\n",
    "    def __init__(self, i=10, depth=3):\n",
    "        self.i = i\n",
    "        self.depth = depth\n",
    "        return\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        labels = np.copy(y)\n",
    "        self.models = [DecisionTreeRegressor(max_depth=self.depth) for _ in range(self.i)]\n",
    "        for model in self.models:\n",
    "            model.fit(X, labels)\n",
    "            preds = model.predict(X)\n",
    "            labels = labels - preds\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = np.array([model.predict(X) for model in self.models])\n",
    "        return np.sum(preds, axis=0) \n",
    "    \n",
    "    def predict_each_model(self, X):\n",
    "        return np.array([model.predict(X) for model in self.models])\n",
    "    \n",
    "    def predict_with_models(self, X, i):\n",
    "        preds = np.array([model.predict(X) for model in self.models[0:i]])\n",
    "        print(preds.shape)\n",
    "        return np.sum(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6779a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_set_columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "house_training_df = pd.read_csv('housing_train.txt', delim_whitespace=True, names=house_set_columns)\n",
    "house_testing_df = pd.read_csv('housing_test.txt', delim_whitespace=True, names=house_set_columns)\n",
    "\n",
    "# combine dataset for normalization\n",
    "house_combined_df = pd.concat([house_training_df, house_testing_df], axis=0)\n",
    "\n",
    "# separate labels before normalization\n",
    "house_combined_labels = house_combined_df.pop(house_combined_df.columns[-1])\n",
    "\n",
    "def normalize_df(df):\n",
    "    mean = df.mean()\n",
    "    std = df.std() \n",
    "    return (df - mean) / std\n",
    "\n",
    "house_combined_df = normalize_df(house_combined_df)\n",
    "\n",
    "# undo concatenation\n",
    "training_len = len(house_training_df)\n",
    "house_training_df = house_combined_df.iloc[:training_len,:]\n",
    "house_training_labels = house_combined_labels.iloc[:training_len]\n",
    "\n",
    "house_testing_df = house_combined_df.iloc[training_len:,:]\n",
    "house_testing_labels = house_combined_labels.iloc[training_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80542015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 3.303818791006094\n",
      "Test MSE: 38.043086457812485\n"
     ]
    }
   ],
   "source": [
    "test2 = GradientBoostedTrees()\n",
    "test2.train(house_training_df, house_training_labels)\n",
    "house_train_preds = test2.predict(house_training_df)\n",
    "house_preds = test2.predict(house_testing_df)\n",
    "\n",
    "def MSE(preds, y):\n",
    "    diffs = y - preds\n",
    "    diffs_squared = diffs ** 2\n",
    "    return diffs_squared.mean()\n",
    "    \n",
    "print(f'Train MSE: {MSE(house_train_preds, house_training_labels)}')\n",
    "print(f'Test MSE: {MSE(house_preds, house_testing_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "172ef439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 433)\n",
      "(2, 433)\n",
      "(3, 433)\n",
      "(4, 433)\n",
      "(5, 433)\n",
      "(6, 433)\n",
      "(7, 433)\n",
      "(8, 433)\n",
      "(9, 433)\n",
      "(10, 433)\n",
      "(1, 74)\n",
      "(2, 74)\n",
      "(3, 74)\n",
      "(4, 74)\n",
      "(5, 74)\n",
      "(6, 74)\n",
      "(7, 74)\n",
      "(8, 74)\n",
      "(9, 74)\n",
      "(10, 74)\n",
      "Individual training MSEs: [15.732147242327171, 10.463519041324895, 7.976053235216596, 6.734890063434734, 5.801848522210734, 5.110293798586951, 4.87164174650844, 4.252660125406961, 3.8419434198597555, 3.303818791006094]\n",
      "Individual testing MSEs: [52.282508772643745, 48.365605634244254, 48.00704499125136, 37.61864699572298, 33.18555597496225, 34.382043611725635, 37.9061049203715, 37.3464071953299, 38.60287065641471, 38.043086457812485]\n"
     ]
    }
   ],
   "source": [
    "house_train_all_preds = [test2.predict_with_models(house_training_df, i) for i in range(1, 11)]\n",
    "house_test_all_preds = [test2.predict_with_models(house_testing_df, i) for i in range(1, 11)]\n",
    "train_mses = []\n",
    "for row in house_train_all_preds:\n",
    "    train_mses.append(MSE(row, house_training_labels))\n",
    "test_mses = []\n",
    "for row in house_test_all_preds:\n",
    "    test_mses.append(MSE(row, house_testing_labels))\n",
    "print(f'Individual training MSEs: {train_mses}')\n",
    "print(f'Individual testing MSEs: {test_mses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af181d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
